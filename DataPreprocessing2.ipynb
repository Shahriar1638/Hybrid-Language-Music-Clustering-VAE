{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1c459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED PREPROCESSING FOR CONVOLUTIONAL VAE\n",
      "============================================================\n",
      "\n",
      "Libraries imported successfully!\n",
      "\n",
      "Configuration loaded!\n",
      "Bangla datasets path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\\Bangla_Datasets\n",
      "English datasets path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\\English_Datasets\n",
      "Output path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data2\n",
      "\n",
      "Spectrogram dimensions: 128 x 128\n",
      "\n",
      "============================================================\n",
      "LOADING METADATA\n",
      "============================================================\n",
      "Metadata shape: (1859, 4)\n",
      "Columns: ['ID', 'language', 'genre', 'lyrics']\n",
      "Loaded 1859 genre entries from metadata\n",
      "Loaded 1859 lyrics entries from metadata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ADVANCED PREPROCESSING FOR CONVOLUTIONAL VAE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'sample_rate': 22050,           # Standard sample rate for audio processing\n",
    "    'duration': 30,                  # Duration in seconds to load from each audio file\n",
    "    'n_mels': 128,                   # Number of mel bands (height of spectrogram)\n",
    "    'n_fft': 2048,                   # FFT window size\n",
    "    'hop_length': 512,               # Hop length for STFT\n",
    "    'n_mfcc': 40,                    # Number of MFCC coefficients\n",
    "    'fixed_time_steps': 128,         # Fixed time dimension for CNN (width of spectrogram)\n",
    "    'max_samples_per_class': 160,    # Maximum samples per class to load\n",
    "    'lyrics_max_features': 100,      # Max TF-IDF features for lyrics\n",
    "}\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = r\"f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\"\n",
    "BANGLA_PATH = os.path.join(BASE_PATH, \"Bangla_Datasets\")\n",
    "ENGLISH_PATH = os.path.join(BASE_PATH, \"English_Datasets\")\n",
    "METADATA_PATH = os.path.join(BASE_PATH, \"updated_metadata.csv\")\n",
    "OUTPUT_PATH = r\"f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data2\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"\\nConfiguration loaded!\")\n",
    "print(f\"Bangla datasets path: {BANGLA_PATH}\")\n",
    "print(f\"English datasets path: {ENGLISH_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")\n",
    "print(f\"\\nSpectrogram dimensions: {CONFIG['n_mels']} x {CONFIG['fixed_time_steps']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOADING METADATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metadata_df = pd.read_csv(METADATA_PATH)\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"Columns: {metadata_df.columns.tolist()}\")\n",
    "\n",
    "# Create lookup dictionaries\n",
    "genre_lookup = dict(zip(metadata_df['ID'].astype(str), metadata_df['genre']))\n",
    "lyrics_lookup = dict(zip(metadata_df['ID'].astype(str), metadata_df['lyrics'].fillna('')))\n",
    "\n",
    "print(f\"Loaded {len(genre_lookup)} genre entries from metadata\")\n",
    "print(f\"Loaded {len(lyrics_lookup)} lyrics entries from metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a32301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_audio_file(file_path):\n",
    "    \"\"\"Load an audio file with error handling.\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(\n",
    "            file_path,\n",
    "            sr=CONFIG['sample_rate'],\n",
    "            duration=CONFIG['duration']\n",
    "        )\n",
    "        \n",
    "        # Pad if audio is shorter than duration\n",
    "        expected_samples = CONFIG['sample_rate'] * CONFIG['duration']\n",
    "        if len(audio) < expected_samples:\n",
    "            audio = np.pad(audio, (0, expected_samples - len(audio)), mode='constant')\n",
    "        \n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def extract_mel_spectrogram(audio, sr):\n",
    "    \"\"\"Extract mel spectrogram with fixed dimensions for CNN.\"\"\"\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=audio, \n",
    "        sr=sr, \n",
    "        n_mels=CONFIG['n_mels'],\n",
    "        n_fft=CONFIG['n_fft'], \n",
    "        hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    # Resize to fixed time steps (width)\n",
    "    if mel_db.shape[1] > CONFIG['fixed_time_steps']:\n",
    "        mel_db = mel_db[:, :CONFIG['fixed_time_steps']]\n",
    "    else:\n",
    "        # Pad with minimum value (silence) instead of 0 (which denotes max volume in dB)\n",
    "        pad_width = CONFIG['fixed_time_steps'] - mel_db.shape[1]\n",
    "        mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant', constant_values=mel_db.min())\n",
    "    \n",
    "    return mel_db\n",
    "\n",
    "\n",
    "def extract_mfcc(audio, sr):\n",
    "    \"\"\"Extract MFCC features with fixed dimensions for CNN.\"\"\"\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=audio, \n",
    "        sr=sr, \n",
    "        n_mfcc=CONFIG['n_mfcc'],\n",
    "        n_fft=CONFIG['n_fft'], \n",
    "        hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    \n",
    "    # Resize to fixed time steps\n",
    "    if mfcc.shape[1] > CONFIG['fixed_time_steps']:\n",
    "        mfcc = mfcc[:, :CONFIG['fixed_time_steps']]\n",
    "    else:\n",
    "        # Pad with minimum value to avoid artifacts\n",
    "        pad_width = CONFIG['fixed_time_steps'] - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant', constant_values=mfcc.min())\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def extract_flattened_features(audio, sr):\n",
    "    \"\"\"\n",
    "    Extract flattened statistical features (for compatibility with MLP-based models).\n",
    "    This matches the format from 1_preprocessing.py\n",
    "    \"\"\"\n",
    "    # Extract mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_mels=CONFIG['n_mels'],\n",
    "        n_fft=CONFIG['n_fft'], hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    # Extract MFCC\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=audio, sr=sr, n_mfcc=CONFIG['n_mfcc'],\n",
    "        n_fft=CONFIG['n_fft'], hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    \n",
    "    # Extract spectral features\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio, hop_length=CONFIG['hop_length'])\n",
    "    rms = librosa.feature.rms(y=audio, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    # Extract chroma features\n",
    "    chroma = librosa.feature.chroma_stft(\n",
    "        y=audio, sr=sr, n_fft=CONFIG['n_fft'], hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    \n",
    "    # Aggregate features into fixed-size vectors using statistical measures\n",
    "    features = []\n",
    "    \n",
    "    # Mel spectrogram statistics\n",
    "    features.extend(np.mean(mel_db, axis=1))\n",
    "    features.extend(np.std(mel_db, axis=1))\n",
    "    \n",
    "    # MFCC statistics\n",
    "    features.extend(np.mean(mfcc, axis=1))\n",
    "    features.extend(np.std(mfcc, axis=1))\n",
    "    \n",
    "    # Spectral feature statistics\n",
    "    for feat in [spectral_centroid, spectral_bandwidth, spectral_rolloff, zcr, rms]:\n",
    "        features.append(np.mean(feat))\n",
    "        features.append(np.std(feat))\n",
    "    \n",
    "    # Chroma statistics\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "    features.extend(np.std(chroma, axis=1))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "print(\"Feature extraction functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485d576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COLLECTING AUDIO FILES\n",
      "============================================================\n",
      "Collecting Bangla song files...\n",
      "Collecting English song files...\n",
      "Total audio files collected: 1766\n",
      "Skipped 93 files (not found in metadata)\n",
      "\n",
      "Total files to process: 1766\n"
     ]
    }
   ],
   "source": [
    "def collect_audio_files():\n",
    "    \"\"\"Collect all audio file paths with their labels from METADATA (not folder names).\"\"\"\n",
    "    audio_files = []\n",
    "    skipped_files = 0\n",
    "    \n",
    "    # Collect Bangla songs\n",
    "    print(\"Collecting Bangla song files...\")\n",
    "    if os.path.exists(BANGLA_PATH):\n",
    "        for genre_folder in os.listdir(BANGLA_PATH):\n",
    "            genre_path = os.path.join(BANGLA_PATH, genre_folder)\n",
    "            if os.path.isdir(genre_path):\n",
    "                files_in_genre = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
    "                # Limit samples per class\n",
    "                files_in_genre = files_in_genre[:CONFIG['max_samples_per_class']]\n",
    "                for audio_file in files_in_genre:\n",
    "                    file_id = os.path.splitext(audio_file)[0]\n",
    "                    if file_id in genre_lookup:\n",
    "                        lyrics = lyrics_lookup.get(file_id, '')\n",
    "                        \n",
    "                        # Filter out samples with empty or insufficient lyrics\n",
    "                        if not isinstance(lyrics, str) or len(lyrics.strip()) < 10:\n",
    "                            skipped_files += 1\n",
    "                            continue\n",
    "                            \n",
    "                        audio_files.append({\n",
    "                            'path': os.path.join(genre_path, audio_file),\n",
    "                            'language': 'bn',\n",
    "                            'genre': genre_lookup[file_id],\n",
    "                            'filename': audio_file,\n",
    "                            'file_id': file_id,\n",
    "                            'lyrics': lyrics\n",
    "                        })\n",
    "                    else:\n",
    "                        skipped_files += 1\n",
    "    \n",
    "    # Collect English songs\n",
    "    print(\"Collecting English song files...\")\n",
    "    if os.path.exists(ENGLISH_PATH):\n",
    "        for genre_folder in os.listdir(ENGLISH_PATH):\n",
    "            genre_path = os.path.join(ENGLISH_PATH, genre_folder)\n",
    "            if os.path.isdir(genre_path):\n",
    "                files_in_genre = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
    "                files_in_genre = files_in_genre[:CONFIG['max_samples_per_class']]\n",
    "                for audio_file in files_in_genre:\n",
    "                    file_id = os.path.splitext(audio_file)[0]\n",
    "                    if file_id in genre_lookup:\n",
    "                        lyrics = lyrics_lookup.get(file_id, '')\n",
    "                        \n",
    "                        # Filter out samples with empty or insufficient lyrics\n",
    "                        if not isinstance(lyrics, str) or len(lyrics.strip()) < 10:\n",
    "                            skipped_files += 1\n",
    "                            continue\n",
    "                            \n",
    "                        audio_files.append({\n",
    "                            'path': os.path.join(genre_path, audio_file),\n",
    "                            'language': 'en',\n",
    "                            'genre': genre_lookup[file_id],\n",
    "                            'filename': audio_file,\n",
    "                            'file_id': file_id,\n",
    "                            'lyrics': lyrics\n",
    "                        })\n",
    "                    else:\n",
    "                        skipped_files += 1\n",
    "    \n",
    "    print(f\"Total audio files collected: {len(audio_files)}\")\n",
    "    if skipped_files > 0:\n",
    "        print(f\"Skipped {skipped_files} files (not found in metadata)\")\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLLECTING AUDIO FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "audio_files = collect_audio_files()\n",
    "print(f\"\\nTotal files to process: {len(audio_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73de3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTING FEATURES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 1766/1766 [09:09<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed: 1766 files\n",
      "Failed to process: 0 files\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTING FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mel_spectrograms = []\n",
    "mfccs = []\n",
    "flattened_features = []\n",
    "labels = []\n",
    "lyrics_list = []\n",
    "metadata_list = []\n",
    "failed_files = []\n",
    "\n",
    "for file_info in tqdm(audio_files, desc=\"Processing audio files\"):\n",
    "    audio, sr = load_audio_file(file_info['path'])\n",
    "    \n",
    "    if audio is not None:\n",
    "        try:\n",
    "            # Extract mel spectrogram (2D for CNN)\n",
    "            mel_spec = extract_mel_spectrogram(audio, sr)\n",
    "            mel_spectrograms.append(mel_spec)\n",
    "            \n",
    "            # Extract MFCC (2D for CNN)\n",
    "            mfcc = extract_mfcc(audio, sr)\n",
    "            mfccs.append(mfcc)\n",
    "            \n",
    "            # Extract flattened features (1D for MLP - same as original preprocessing)\n",
    "            flat_feat = extract_flattened_features(audio, sr)\n",
    "            flattened_features.append(flat_feat)\n",
    "            \n",
    "            # Collect labels and metadata\n",
    "            labels.append(file_info['genre'])\n",
    "            lyrics_list.append(file_info['lyrics'])\n",
    "            metadata_list.append({\n",
    "                'language': file_info['language'],\n",
    "                'genre': file_info['genre'],\n",
    "                'filename': file_info['filename'],\n",
    "                'file_id': file_info['file_id']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            failed_files.append((file_info['path'], str(e)))\n",
    "    else:\n",
    "        failed_files.append((file_info['path'], \"Failed to load\"))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "mel_spectrograms = np.array(mel_spectrograms)\n",
    "mfccs = np.array(mfccs)\n",
    "flattened_features = np.array(flattened_features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"\\nSuccessfully processed: {len(mel_spectrograms)} files\")\n",
    "print(f\"Failed to process: {len(failed_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e589f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING LYRICS EMBEDDINGS\n",
      "============================================================\n",
      "Lyrics embeddings shape: (1766, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING LYRICS EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def create_lyrics_embeddings(lyrics_list, max_features=100):\n",
    "    \"\"\"Create TF-IDF embeddings for lyrics.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "    # Handle empty lyrics\n",
    "    lyrics_cleaned = [l if l and len(str(l)) > 0 else ' ' for l in lyrics_list]\n",
    "    embeddings = vectorizer.fit_transform(lyrics_cleaned).toarray()\n",
    "    return embeddings, vectorizer\n",
    "\n",
    "\n",
    "lyrics_embeddings, tfidf_vectorizer = create_lyrics_embeddings(\n",
    "    lyrics_list, \n",
    "    max_features=CONFIG['lyrics_max_features']\n",
    ")\n",
    "print(f\"Lyrics embeddings shape: {lyrics_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2115de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE EXTRACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "1. Mel Spectrograms (for CNN):\n",
      "   Shape: (1766, 128, 128)\n",
      "   Dimensions: 128 (mel bands) x 128 (time steps)\n",
      "\n",
      "2. MFCCs (for CNN):\n",
      "   Shape: (1766, 40, 128)\n",
      "   Dimensions: 40 (coefficients) x 128 (time steps)\n",
      "\n",
      "3. Flattened Features (for MLP - backward compatible):\n",
      "   Shape: (1766, 370)\n",
      "   Feature vector size: 370\n",
      "\n",
      "4. Lyrics Embeddings (TF-IDF):\n",
      "   Shape: (1766, 100)\n",
      "\n",
      "5. Number of samples: 1766\n",
      "   Number of unique genres: 8\n",
      "\n",
      "Label distribution:\n",
      "  - traditional: 260\n",
      "  - hiphop: 258\n",
      "  - pop: 250\n",
      "  - rock: 249\n",
      "  - metal: 232\n",
      "  - disco: 195\n",
      "  - jazz: 163\n",
      "  - indie: 159\n",
      "\n",
      "Language distribution:\n",
      "  - Bangla: 913\n",
      "  - English: 853\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. Mel Spectrograms (for CNN):\")\n",
    "print(f\"   Shape: {mel_spectrograms.shape}\")\n",
    "print(f\"   Dimensions: {mel_spectrograms.shape[1]} (mel bands) x {mel_spectrograms.shape[2]} (time steps)\")\n",
    "\n",
    "print(f\"\\n2. MFCCs (for CNN):\")\n",
    "print(f\"   Shape: {mfccs.shape}\")\n",
    "print(f\"   Dimensions: {mfccs.shape[1]} (coefficients) x {mfccs.shape[2]} (time steps)\")\n",
    "\n",
    "print(f\"\\n3. Flattened Features (for MLP - backward compatible):\")\n",
    "print(f\"   Shape: {flattened_features.shape}\")\n",
    "print(f\"   Feature vector size: {flattened_features.shape[1]}\")\n",
    "\n",
    "print(f\"\\n4. Lyrics Embeddings (TF-IDF):\")\n",
    "print(f\"   Shape: {lyrics_embeddings.shape}\")\n",
    "\n",
    "print(f\"\\n5. Number of samples: {len(labels)}\")\n",
    "print(f\"   Number of unique genres: {len(np.unique(labels))}\")\n",
    "\n",
    "# Label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "label_counts = pd.Series(labels).value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  - {label}: {count}\")\n",
    "\n",
    "# Language distribution\n",
    "languages = [m['language'] for m in metadata_list]\n",
    "lang_counts = pd.Series(languages).value_counts()\n",
    "print(\"\\nLanguage distribution:\")\n",
    "for lang, count in lang_counts.items():\n",
    "    print(f\"  - {'Bangla' if lang == 'bn' else 'English'}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42cae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NORMALIZING FEATURES\n",
      "============================================================\n",
      "\n",
      "NaN values in flattened features: 0\n",
      "Inf values in flattened features: 0\n",
      "\n",
      "After normalization:\n",
      "  - Mel spectrograms mean: 0.0000, std: 1.0000\n",
      "  - MFCCs mean: 0.0000, std: 1.0000\n",
      "  - Flattened features mean: 0.0000, std: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NORMALIZING FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Normalize mel spectrograms (per-sample normalization)\n",
    "mel_scaler = StandardScaler()\n",
    "mel_flat = mel_spectrograms.reshape(len(mel_spectrograms), -1)\n",
    "mel_normalized_flat = mel_scaler.fit_transform(mel_flat)\n",
    "mel_normalized = mel_normalized_flat.reshape(mel_spectrograms.shape)\n",
    "\n",
    "# Normalize MFCCs\n",
    "mfcc_scaler = StandardScaler()\n",
    "mfcc_flat = mfccs.reshape(len(mfccs), -1)\n",
    "mfcc_normalized_flat = mfcc_scaler.fit_transform(mfcc_flat)\n",
    "mfcc_normalized = mfcc_normalized_flat.reshape(mfccs.shape)\n",
    "\n",
    "# Normalize flattened features\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check for NaN or inf values\n",
    "print(f\"\\nNaN values in flattened features: {np.isnan(flattened_features).sum()}\")\n",
    "print(f\"Inf values in flattened features: {np.isinf(flattened_features).sum()}\")\n",
    "\n",
    "# Replace inf with NaN, then impute\n",
    "features_clean = np.where(np.isinf(flattened_features), np.nan, flattened_features)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features_clean)\n",
    "\n",
    "# Normalize\n",
    "flat_scaler = StandardScaler()\n",
    "features_normalized = flat_scaler.fit_transform(features_imputed)\n",
    "\n",
    "print(f\"\\nAfter normalization:\")\n",
    "print(f\"  - Mel spectrograms mean: {mel_normalized.mean():.4f}, std: {mel_normalized.std():.4f}\")\n",
    "print(f\"  - MFCCs mean: {mfcc_normalized.mean():.4f}, std: {mfcc_normalized.std():.4f}\")\n",
    "print(f\"  - Flattened features mean: {features_normalized.mean():.4f}, std: {features_normalized.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4190be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING PREPROCESSED DATA\n",
      "============================================================\n",
      "\n",
      "Files saved to: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data2\n",
      "\n",
      "Saved files:\n",
      "  FOR CONVOLUTIONAL VAE (3_advanced_vae_clustering.py):\n",
      "    - mel_spectrograms_raw.npy\n",
      "    - mel_spectrograms_normalized.npy\n",
      "    - mfccs_raw.npy\n",
      "    - mfccs_normalized.npy\n",
      "    - lyrics_embeddings.npy\n",
      "\n",
      "  FOR MLP-BASED VAE (2_vae_clustering.py - backward compatible):\n",
      "    - features_raw.npy\n",
      "    - features_normalized.npy\n",
      "\n",
      "  COMMON FILES:\n",
      "    - labels.npy\n",
      "    - metadata.csv\n",
      "    - mel_scaler.pkl\n",
      "    - mfcc_scaler.pkl\n",
      "    - flat_scaler.pkl\n",
      "    - imputer.pkl\n",
      "    - tfidf_vectorizer.pkl\n",
      "    - config.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING PREPROCESSED DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create DataFrame with metadata\n",
    "metadata_df_out = pd.DataFrame(metadata_list)\n",
    "metadata_df_out['label'] = labels\n",
    "\n",
    "# Save 2D features for CNN (mel spectrograms)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'mel_spectrograms_raw.npy'), mel_spectrograms)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'mel_spectrograms_normalized.npy'), mel_normalized)\n",
    "\n",
    "# Save MFCCs\n",
    "np.save(os.path.join(OUTPUT_PATH, 'mfccs_raw.npy'), mfccs)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'mfccs_normalized.npy'), mfcc_normalized)\n",
    "\n",
    "# Save flattened features (backward compatible with 2_vae_clustering.py)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'features_raw.npy'), flattened_features)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'features_normalized.npy'), features_normalized)\n",
    "\n",
    "# Save lyrics embeddings\n",
    "np.save(os.path.join(OUTPUT_PATH, 'lyrics_embeddings.npy'), lyrics_embeddings)\n",
    "\n",
    "# Save labels\n",
    "np.save(os.path.join(OUTPUT_PATH, 'labels.npy'), labels)\n",
    "\n",
    "# Save metadata\n",
    "metadata_df_out.to_csv(os.path.join(OUTPUT_PATH, 'metadata.csv'), index=False)\n",
    "\n",
    "# Save scalers and vectorizer for later use\n",
    "with open(os.path.join(OUTPUT_PATH, 'mel_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(mel_scaler, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'mfcc_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(mfcc_scaler, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'flat_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(flat_scaler, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'imputer.pkl'), 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'tfidf_vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Save configuration\n",
    "with open(os.path.join(OUTPUT_PATH, 'config.pkl'), 'wb') as f:\n",
    "    pickle.dump(CONFIG, f)\n",
    "\n",
    "print(f\"\\nFiles saved to: {OUTPUT_PATH}\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  FOR CONVOLUTIONAL VAE (3_advanced_vae_clustering.py):\")\n",
    "print(\"    - mel_spectrograms_raw.npy\")\n",
    "print(\"    - mel_spectrograms_normalized.npy\")\n",
    "print(\"    - mfccs_raw.npy\")\n",
    "print(\"    - mfccs_normalized.npy\")\n",
    "print(\"    - lyrics_embeddings.npy\")\n",
    "print(\"\\n  FOR MLP-BASED VAE (2_vae_clustering.py - backward compatible):\")\n",
    "print(\"    - features_raw.npy\")\n",
    "print(\"    - features_normalized.npy\")\n",
    "print(\"\\n  COMMON FILES:\")\n",
    "print(\"    - labels.npy\")\n",
    "print(\"    - metadata.csv\")\n",
    "print(\"    - mel_scaler.pkl\")\n",
    "print(\"    - mfcc_scaler.pkl\")\n",
    "print(\"    - flat_scaler.pkl\")\n",
    "print(\"    - imputer.pkl\")\n",
    "print(\"    - tfidf_vectorizer.pkl\")\n",
    "print(\"    - config.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
