{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c57791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f09fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "Bangla datasets path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\\Bangla_Datasets\n",
      "English datasets path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\\English_Datasets\n",
      "Output path: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    'sample_rate': 22050,          # Standard sample rate for audio processing\n",
    "    'duration': 30,                 # Duration in seconds to load from each audio file\n",
    "    'n_mels': 128,                  # Number of mel bands\n",
    "    'n_fft': 2048,                  # FFT window size\n",
    "    'hop_length': 512,              # Hop length for STFT\n",
    "    'n_mfcc': 40,                   # Number of MFCC coefficients\n",
    "    'max_samples_per_class': 160,   # Maximum samples per class to load (for faster processing)\n",
    "}\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = r\"f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\Datasets\"\n",
    "BANGLA_PATH = os.path.join(BASE_PATH, \"Bangla_Datasets\")\n",
    "ENGLISH_PATH = os.path.join(BASE_PATH, \"English_Datasets\")\n",
    "METADATA_PATH = os.path.join(BASE_PATH, \"updated_metadata.csv\")\n",
    "OUTPUT_PATH = r\"f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded!\")\n",
    "print(f\"Bangla datasets path: {BANGLA_PATH}\")\n",
    "print(f\"English datasets path: {ENGLISH_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4b1412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined!\n",
      "Audio loading function defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_mel_spectrogram(audio, sr):\n",
    "    \"\"\"Extract mel spectrogram from audio signal.\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mels=CONFIG['n_mels'],\n",
    "        n_fft=CONFIG['n_fft'],\n",
    "        hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    # Convert to log scale (dB)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "\n",
    "def extract_mfcc(audio, sr):\n",
    "    \"\"\"Extract MFCC features from audio signal.\"\"\"\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mfcc=CONFIG['n_mfcc'],\n",
    "        n_fft=CONFIG['n_fft'],\n",
    "        hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def extract_spectral_features(audio, sr):\n",
    "    \"\"\"Extract various spectral features.\"\"\"\n",
    "    # Spectral centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    # Spectral bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    # Spectral rolloff\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    # Zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    # RMS energy\n",
    "    rms = librosa.feature.rms(y=audio, hop_length=CONFIG['hop_length'])\n",
    "    \n",
    "    return {\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'spectral_rolloff': spectral_rolloff,\n",
    "        'zcr': zcr,\n",
    "        'rms': rms\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_chroma_features(audio, sr):\n",
    "    \"\"\"Extract chroma features.\"\"\"\n",
    "    chroma = librosa.feature.chroma_stft(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_fft=CONFIG['n_fft'],\n",
    "        hop_length=CONFIG['hop_length']\n",
    "    )\n",
    "    return chroma\n",
    "\n",
    "\n",
    "def extract_all_features(audio, sr):\n",
    "    \"\"\"Extract all features and return as a fixed-size feature vector.\"\"\"\n",
    "    # Extract mel spectrogram\n",
    "    mel_spec = extract_mel_spectrogram(audio, sr)\n",
    "    \n",
    "    # Extract MFCC\n",
    "    mfcc = extract_mfcc(audio, sr)\n",
    "    \n",
    "    # Extract spectral features\n",
    "    spectral = extract_spectral_features(audio, sr)\n",
    "    \n",
    "    # Extract chroma features\n",
    "    chroma = extract_chroma_features(audio, sr)\n",
    "    \n",
    "    # Aggregate features into fixed-size vectors using statistical measures\n",
    "    features = []\n",
    "    \n",
    "    # Mel spectrogram statistics (mean and std across time for each mel band)\n",
    "    features.extend(np.mean(mel_spec, axis=1))\n",
    "    features.extend(np.std(mel_spec, axis=1))\n",
    "    \n",
    "    # MFCC statistics\n",
    "    features.extend(np.mean(mfcc, axis=1))\n",
    "    features.extend(np.std(mfcc, axis=1))\n",
    "    \n",
    "    # Spectral feature statistics\n",
    "    for name, feat in spectral.items():\n",
    "        features.append(np.mean(feat))\n",
    "        features.append(np.std(feat))\n",
    "    \n",
    "    # Chroma statistics\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "    features.extend(np.std(chroma, axis=1))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "print(\"Feature extraction functions defined!\")\n",
    "\n",
    "def load_audio_file(file_path):\n",
    "    \"\"\"Load an audio file with error handling.\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(\n",
    "            file_path,\n",
    "            sr=CONFIG['sample_rate'],\n",
    "            duration=CONFIG['duration']\n",
    "        )\n",
    "        \n",
    "        # Pad if audio is shorter than duration\n",
    "        expected_samples = CONFIG['sample_rate'] * CONFIG['duration']\n",
    "        if len(audio) < expected_samples:\n",
    "            audio = np.pad(audio, (0, expected_samples - len(audio)), mode='constant')\n",
    "        \n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"Audio loading function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f7555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Bangla song files...\n",
      "Collecting English song files...\n",
      "Total audio files collected: 2119\n",
      "\n",
      "Total files to process: 2119\n",
      "Processing 2119 audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 2119/2119 [09:53<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed: 2119 files\n",
      "Failed to process: 0 files\n",
      "\n",
      "Feature matrix shape: (2119, 370)\n",
      "Number of labels: 2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collect_audio_files():\n",
    "    \"\"\"Collect all audio file paths with their labels.\"\"\"\n",
    "    audio_files = []\n",
    "    \n",
    "    # Collect Bangla songs\n",
    "    print(\"Collecting Bangla song files...\")\n",
    "    if os.path.exists(BANGLA_PATH):\n",
    "        for genre_folder in os.listdir(BANGLA_PATH):\n",
    "            genre_path = os.path.join(BANGLA_PATH, genre_folder)\n",
    "            if os.path.isdir(genre_path):\n",
    "                files_in_genre = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
    "                # Limit samples per class\n",
    "                files_in_genre = files_in_genre[:CONFIG['max_samples_per_class']]\n",
    "                for audio_file in files_in_genre:\n",
    "                    audio_files.append({\n",
    "                        'path': os.path.join(genre_path, audio_file),\n",
    "                        'language': 'bn',\n",
    "                        'genre': genre_folder,\n",
    "                        'filename': audio_file\n",
    "                    })\n",
    "    \n",
    "    # Collect English songs\n",
    "    print(\"Collecting English song files...\")\n",
    "    if os.path.exists(ENGLISH_PATH):\n",
    "        for genre_folder in os.listdir(ENGLISH_PATH):\n",
    "            genre_path = os.path.join(ENGLISH_PATH, genre_folder)\n",
    "            if os.path.isdir(genre_path):\n",
    "                files_in_genre = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
    "                # Limit samples per class\n",
    "                files_in_genre = files_in_genre[:CONFIG['max_samples_per_class']]\n",
    "                for audio_file in files_in_genre:\n",
    "                    audio_files.append({\n",
    "                        'path': os.path.join(genre_path, audio_file),\n",
    "                        'language': 'en',\n",
    "                        'genre': genre_folder,\n",
    "                        'filename': audio_file\n",
    "                    })\n",
    "    \n",
    "    print(f\"Total audio files collected: {len(audio_files)}\")\n",
    "    return audio_files\n",
    "\n",
    "# Collect files\n",
    "audio_files = collect_audio_files()\n",
    "print(f\"\\nTotal files to process: {len(audio_files)}\")\n",
    "\n",
    "\n",
    "def process_audio_files(audio_files):\n",
    "    \"\"\"Process all audio files and extract features.\"\"\"\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_metadata = []\n",
    "    failed_files = []\n",
    "    \n",
    "    print(f\"Processing {len(audio_files)} audio files...\")\n",
    "    \n",
    "    for file_info in tqdm(audio_files, desc=\"Extracting features\"):\n",
    "        file_path = file_info['path']\n",
    "        \n",
    "        # Load audio\n",
    "        audio, sr = load_audio_file(file_path)\n",
    "        \n",
    "        if audio is not None:\n",
    "            try:\n",
    "                # Extract features\n",
    "                features = extract_all_features(audio, sr)\n",
    "                \n",
    "                all_features.append(features)\n",
    "                all_labels.append(file_info['genre'])\n",
    "                all_metadata.append({\n",
    "                    'language': file_info['language'],\n",
    "                    'genre': file_info['genre'],\n",
    "                    'filename': file_info['filename']\n",
    "                })\n",
    "            except Exception as e:\n",
    "                failed_files.append((file_path, str(e)))\n",
    "        else:\n",
    "            failed_files.append((file_path, \"Failed to load\"))\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed: {len(all_features)} files\")\n",
    "    print(f\"Failed to process: {len(failed_files)} files\")\n",
    "    \n",
    "    return np.array(all_features), all_labels, all_metadata, failed_files\n",
    "\n",
    "# Process files\n",
    "features, labels, metadata, failed = process_audio_files(audio_files)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {features.shape}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76ea6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE EXTRACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Feature vector size per sample: 370\n",
      "Total number of samples: 2119\n",
      "\n",
      "Feature breakdown:\n",
      "  - Mel spectrogram (mean + std): 256 features\n",
      "  - MFCC (mean + std): 80 features\n",
      "  - Spectral features (5 types × 2 stats): 10 features\n",
      "  - Chroma features (mean + std): 24 features\n",
      "\n",
      "Label distribution:\n",
      "  - Adhunik: 160\n",
      "  - Folk: 160\n",
      "  - Hiphop: 160\n",
      "  - Indie: 160\n",
      "  - Metal: 160\n",
      "  - Pop: 160\n",
      "  - Rock: 160\n",
      "  - blues: 100\n",
      "  - classical: 100\n",
      "  - country: 100\n",
      "  - disco: 100\n",
      "  - hiphop: 100\n",
      "  - metal: 100\n",
      "  - reggae: 100\n",
      "  - pop: 100\n",
      "  - rock: 100\n",
      "  - jazz: 99\n",
      "\n",
      "Language distribution:\n",
      "  - Bangla: 1120\n",
      "  - English: 999\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFeature vector size per sample: {features.shape[1]}\")\n",
    "print(f\"Total number of samples: {features.shape[0]}\")\n",
    "\n",
    "# Feature breakdown\n",
    "print(\"\\nFeature breakdown:\")\n",
    "print(f\"  - Mel spectrogram (mean + std): {CONFIG['n_mels'] * 2} features\")\n",
    "print(f\"  - MFCC (mean + std): {CONFIG['n_mfcc'] * 2} features\")\n",
    "print(f\"  - Spectral features (5 types × 2 stats): 10 features\")\n",
    "print(f\"  - Chroma features (mean + std): 24 features\")\n",
    "\n",
    "# Label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "label_counts = pd.Series(labels).value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  - {label}: {count}\")\n",
    "\n",
    "# Language distribution\n",
    "languages = [m['language'] for m in metadata]\n",
    "lang_counts = pd.Series(languages).value_counts()\n",
    "print(\"\\nLanguage distribution:\")\n",
    "for lang, count in lang_counts.items():\n",
    "    print(f\"  - {'Bangla' if lang == 'bn' else 'English'}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080d0bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "NaN values in features: 0\n",
      "Inf values in features: 0\n",
      "\n",
      "After preprocessing:\n",
      "  - NaN values: 0\n",
      "  - Feature mean (should be ~0): -0.0000\n",
      "  - Feature std (should be ~1): 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for NaN or inf values\n",
    "print(f\"\\nNaN values in features: {np.isnan(features).sum()}\")\n",
    "print(f\"Inf values in features: {np.isinf(features).sum()}\")\n",
    "\n",
    "# Replace inf with NaN, then impute\n",
    "features_clean = np.where(np.isinf(features), np.nan, features)\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features_clean)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features_imputed)\n",
    "\n",
    "print(f\"\\nAfter preprocessing:\")\n",
    "print(f\"  - NaN values: {np.isnan(features_normalized).sum()}\")\n",
    "print(f\"  - Feature mean (should be ~0): {features_normalized.mean():.4f}\")\n",
    "print(f\"  - Feature std (should be ~1): {features_normalized.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a7b2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING PREPROCESSED DATA\n",
      "============================================================\n",
      "\n",
      "Files saved to: f:\\BRACU\\Semester 12 Final\\CSE425\\FInal_project\\processed_data\n",
      "  - features_raw.npy\n",
      "  - features_normalized.npy\n",
      "  - labels.npy\n",
      "  - metadata.csv\n",
      "  - scaler.pkl\n",
      "  - imputer.pkl\n",
      "  - config.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING PREPROCESSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create DataFrame with metadata\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df['label'] = labels\n",
    "\n",
    "# Save features\n",
    "np.save(os.path.join(OUTPUT_PATH, 'features_raw.npy'), features)\n",
    "np.save(os.path.join(OUTPUT_PATH, 'features_normalized.npy'), features_normalized)\n",
    "\n",
    "# Save labels\n",
    "np.save(os.path.join(OUTPUT_PATH, 'labels.npy'), np.array(labels))\n",
    "\n",
    "# Save metadata\n",
    "metadata_df.to_csv(os.path.join(OUTPUT_PATH, 'metadata.csv'), index=False)\n",
    "\n",
    "# Save scaler and imputer for later use\n",
    "with open(os.path.join(OUTPUT_PATH, 'scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'imputer.pkl'), 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "# Save configuration\n",
    "with open(os.path.join(OUTPUT_PATH, 'config.pkl'), 'wb') as f:\n",
    "    pickle.dump(CONFIG, f)\n",
    "\n",
    "print(f\"\\nFiles saved to: {OUTPUT_PATH}\")\n",
    "print(\"  - features_raw.npy\")\n",
    "print(\"  - features_normalized.npy\")\n",
    "print(\"  - labels.npy\")\n",
    "print(\"  - metadata.csv\")\n",
    "print(\"  - scaler.pkl\")\n",
    "print(\"  - imputer.pkl\")\n",
    "print(\"  - config.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1efe3073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "\n",
      "Loaded features shape: (2119, 370)\n",
      "Loaded labels count: 2119\n",
      "Loaded metadata shape: (2119, 4)\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "You can now proceed to the VAE training and clustering notebook.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and verify\n",
    "features_loaded = np.load(os.path.join(OUTPUT_PATH, 'features_normalized.npy'))\n",
    "labels_loaded = np.load(os.path.join(OUTPUT_PATH, 'labels.npy'), allow_pickle=True)\n",
    "metadata_loaded = pd.read_csv(os.path.join(OUTPUT_PATH, 'metadata.csv'))\n",
    "\n",
    "print(f\"\\nLoaded features shape: {features_loaded.shape}\")\n",
    "print(f\"Loaded labels count: {len(labels_loaded)}\")\n",
    "print(f\"Loaded metadata shape: {metadata_loaded.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYou can now proceed to the VAE training and clustering notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
